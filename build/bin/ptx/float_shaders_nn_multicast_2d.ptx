//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33567101
// Cuda compilation tools, release 12.3, V12.3.107
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_75
.address_size 64

	// .globl	__intersection__nn_multicast_2d
.weak .global .align 4 .b8 _ZZN4cuda3std3__48__detail21__stronger_order_cudaEiiE7__xform[16] = {3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 3};
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust8cuda_cub3parE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_1E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_2E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_3E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_4E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_5E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_6E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_7E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_8E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_9E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders3_10E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust3seqE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b4cuda3std3__48in_placeE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b4cuda3std6ranges3__45__cpo4swapE[1];
.extern .const .align 8 .b8 params[152];

.visible .entry __intersection__nn_multicast_2d()
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<25>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<19>;


	mov.u32 	%r3, 0;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	mov.u32 	%r5, 1;
	// begin inline asm
	call (%r4), _optix_get_payload, (%r5);
	// end inline asm
	// begin inline asm
	call (%r6), _optix_read_primitive_idx, ();
	// end inline asm
	ld.const.u64 	%rd5, [params+40];
	cvta.to.global.u64 	%rd6, %rd5;
	mul.wide.u32 	%rd7, %r2, 8;
	add.s64 	%rd1, %rd6, %rd7;
	ld.const.u64 	%rd8, [params+56];
	cvta.to.global.u64 	%rd9, %rd8;
	mul.wide.u32 	%rd10, %r6, 8;
	add.s64 	%rd2, %rd9, %rd10;
	ld.const.f32 	%f1, [params+120];
	// begin inline asm
	call (%r8), _optix_get_launch_dimension_y, ();
	// end inline asm
	rem.u32 	%r13, %r6, %r8;
	ld.const.u64 	%rd11, [params+128];
	cvta.to.global.u64 	%rd12, %rd11;
	red.global.add.u32 	[%rd12], 1;
	// begin inline asm
	call (%r11), _optix_get_launch_index_y, ();
	// end inline asm
	setp.ne.s32 	%p1, %r11, %r13;
	@%p1 bra 	$L__BB0_7;

	ld.global.f32 	%f3, [%rd2];
	sub.f32 	%f4, %f3, %f1;
	ld.global.f32 	%f5, [%rd1];
	setp.ltu.f32 	%p2, %f5, %f4;
	add.f32 	%f6, %f1, %f3;
	setp.gtu.f32 	%p3, %f5, %f6;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_7;

	ld.global.f32 	%f7, [%rd2+4];
	sub.f32 	%f8, %f7, %f1;
	ld.global.f32 	%f9, [%rd1+4];
	setp.ltu.f32 	%p5, %f9, %f8;
	add.f32 	%f10, %f1, %f7;
	setp.gtu.f32 	%p6, %f9, %f10;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB0_7;

	ld.global.v2.f32 	{%f11, %f12}, [%rd1];
	ld.global.v2.f32 	{%f15, %f16}, [%rd2];
	sub.f32 	%f19, %f11, %f15;
	sub.f32 	%f20, %f12, %f16;
	mul.f32 	%f21, %f20, %f20;
	fma.rn.f32 	%f2, %f19, %f19, %f21;
	mov.u32 	%r16, 2;
	// begin inline asm
	call (%r15), _optix_get_payload, (%r16);
	// end inline asm
	mov.b32 	%f22, %r15;
	setp.geu.f32 	%p8, %f2, %f22;
	@%p8 bra 	$L__BB0_5;

	mov.b32 	%r18, %f2;
	// begin inline asm
	call _optix_set_payload, (%r16, %r18);
	// end inline asm

$L__BB0_5:
	ld.const.u64 	%rd13, [params+112];
	cvta.to.global.u64 	%rd14, %rd13;
	ld.global.f32 	%f23, [%rd14];
	add.s32 	%r20, %r4, 1;
	mov.u32 	%r19, 1;
	// begin inline asm
	call _optix_set_payload, (%r19, %r20);
	// end inline asm
	setp.gtu.f32 	%p9, %f2, %f23;
	@%p9 bra 	$L__BB0_7;

	ld.const.u64 	%rd15, [params+136];
	cvta.to.global.u64 	%rd16, %rd15;
	red.global.add.u32 	[%rd16], 1;
	ld.const.u64 	%rd17, [params+144];
	cvta.to.global.u64 	%rd18, %rd17;
	red.global.add.u32 	[%rd18], %r4;
	mov.f32 	%f24, 0f00000000;
	mov.u32 	%r22, 0;
	// begin inline asm
	call (%r21), _optix_report_intersection_0, (%f24, %r22);
	// end inline asm

$L__BB0_7:
	ret;

}
	// .globl	__anyhit__nn_multicast_2d
.visible .entry __anyhit__nn_multicast_2d()
{



	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm
	ret;

}
	// .globl	__raygen__nn_multicast_2d
.visible .entry __raygen__nn_multicast_2d()
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<32>;
	.reg .b32 	%r<140>;
	.reg .b64 	%rd<33>;


	// begin inline asm
	call (%r135), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd32, %r135;
	ld.const.u64 	%rd2, [params+8];
	setp.le.u64 	%p1, %rd2, %rd32;
	@%p1 bra 	$L__BB2_16;

	ld.const.u64 	%rd15, [params];
	cvta.to.global.u64 	%rd3, %rd15;
	ld.const.u64 	%rd16, [params+40];
	cvta.to.global.u64 	%rd4, %rd16;
	ld.const.u64 	%rd5, [params+88];
	ld.const.u64 	%rd17, [params+72];
	cvta.to.global.u64 	%rd6, %rd17;
	ld.const.u64 	%rd18, [params+80];
	cvta.to.global.u64 	%rd7, %rd18;
	ld.const.u64 	%rd19, [params+32];
	cvta.to.global.u64 	%rd8, %rd19;
	ld.const.u64 	%rd20, [params+16];
	cvta.to.global.u64 	%rd9, %rd20;
	ld.const.u64 	%rd21, [params+112];
	cvta.to.global.u64 	%rd10, %rd21;
	ld.const.v2.f32 	{%f7, %f8}, [params+96];
	ld.const.v2.f32 	{%f9, %f10}, [params+104];
	sub.f32 	%f3, %f9, %f7;
	sub.f32 	%f4, %f10, %f8;
	// begin inline asm
	call (%r52), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r126), _optix_get_launch_dimension_y, ();
	// end inline asm
	add.s32 	%r129, %r126, -1;
	// begin inline asm
	call (%r132), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB2_2:
	shl.b64 	%rd23, %rd32, 2;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u32 	%r93, [%rd24];
	mul.wide.u32 	%rd25, %r93, 8;
	add.s64 	%rd26, %rd4, %rd25;
	cvt.rn.f32.s32 	%f22, %r52;
	ld.global.f32 	%f23, [%rd26];
	sub.f32 	%f24, %f23, %f7;
	div.rn.f32 	%f25, %f24, %f3;
	add.f32 	%f13, %f25, %f22;
	ld.global.f32 	%f26, [%rd26+4];
	sub.f32 	%f27, %f26, %f8;
	div.rn.f32 	%f28, %f27, %f4;
	add.f32 	%f14, %f28, %f22;
	mov.f32 	%f18, 0f3F800000;
	mov.f32 	%f20, 0f00800000;
	mov.f32 	%f21, 0f00000000;
	mov.u32 	%r87, 255;
	mov.u32 	%r90, 1;
	mov.u32 	%r92, 3;
	mov.u32 	%r95, 2139095039;
	mov.u32 	%r124, 0;
	// begin inline asm
	call(%r54,%r55,%r56,%r57,%r58,%r59,%r60,%r61,%r62,%r63,%r64,%r65,%r66,%r67,%r68,%r69,%r70,%r71,%r72,%r73,%r74,%r75,%r76,%r77,%r78,%r79,%r80,%r81,%r82,%r83,%r84,%r85),_optix_trace_typed_32,(%r124,%rd5,%f13,%f14,%f21,%f21,%f21,%f18,%f21,%f20,%f21,%r87,%r124,%r124,%r90,%r124,%r92,%r93,%r124,%r95,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124,%r124);
	// end inline asm
	mov.b32 	%f5, %r56;
	setp.eq.f32 	%p2, %f5, 0f7F7FFFFF;
	add.s64 	%rd12, %rd6, %rd23;
	@%p2 bra 	$L__BB2_6;

	ld.global.u32 	%r136, [%rd12];

$L__BB2_4:
	mov.b32 	%f29, %r136;
	setp.leu.f32 	%p3, %f29, %f5;
	@%p3 bra 	$L__BB2_6;

	atom.global.cas.b32 	%r38, [%rd12], %r136, %r56;
	setp.ne.s32 	%p4, %r38, %r136;
	mov.u32 	%r136, %r38;
	@%p4 bra 	$L__BB2_4;

$L__BB2_6:
	add.s64 	%rd29, %rd7, %rd23;
	atom.global.add.u32 	%r128, [%rd29], 1;
	setp.ne.s32 	%p5, %r128, %r129;
	@%p5 bra 	$L__BB2_15;

	ld.global.u32 	%r138, [%rd12];

$L__BB2_8:
	mov.b32 	%f30, %r138;
	setp.geu.f32 	%p6, %f30, 0f00000000;
	@%p6 bra 	$L__BB2_10;

	mov.u32 	%r130, 0;
	atom.global.cas.b32 	%r42, [%rd12], %r138, %r130;
	setp.ne.s32 	%p7, %r42, %r138;
	mov.u32 	%r138, %r42;
	@%p7 bra 	$L__BB2_8;

$L__BB2_10:
	mov.b32 	%f6, %r138;
	setp.eq.f32 	%p8, %f6, 0f7F7FFFFF;
	@%p8 bra 	$L__BB2_14;
	bra.uni 	$L__BB2_11;

$L__BB2_14:
	atom.global.add.u32 	%r131, [%rd8], 1;
	mul.wide.u32 	%rd30, %r131, 4;
	add.s64 	%rd31, %rd9, %rd30;
	st.global.u32 	[%rd31], %r54;
	bra.uni 	$L__BB2_15;

$L__BB2_11:
	ld.global.u32 	%r139, [%rd10];

$L__BB2_12:
	mov.b32 	%f31, %r139;
	setp.geu.f32 	%p9, %f31, %f6;
	@%p9 bra 	$L__BB2_15;

	atom.global.cas.b32 	%r46, [%rd10], %r139, %r138;
	setp.eq.s32 	%p10, %r46, %r139;
	mov.u32 	%r139, %r46;
	@%p10 bra 	$L__BB2_15;
	bra.uni 	$L__BB2_12;

$L__BB2_15:
	add.s32 	%r135, %r132, %r135;
	cvt.u64.u32 	%rd32, %r135;
	setp.gt.u64 	%p11, %rd2, %rd32;
	@%p11 bra 	$L__BB2_2;

$L__BB2_16:
	ret;

}
	// .weak	_ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv
.weak .entry _ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv()
{



	ret;

}

