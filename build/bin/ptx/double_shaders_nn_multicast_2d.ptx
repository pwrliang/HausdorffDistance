//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33567101
// Cuda compilation tools, release 12.3, V12.3.107
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_75
.address_size 64

	// .globl	__intersection__nn_multicast_2d
.weak .global .align 4 .b8 _ZZN4cuda3std3__48__detail21__stronger_order_cudaEiiE7__xform[16] = {3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 3};
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust8cuda_cub3parE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_1E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_2E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_3E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_4E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_5E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_6E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_7E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_8E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders2_9E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust12placeholders3_10E[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b6thrust3seqE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b4cuda3std3__48in_placeE[1];
.global .align 1 .b8 __nv_static_48__982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b__ZN57_INTERNAL_982f108f_26_shaders_nn_multicast_2d_cu_341a4b2b4cuda3std6ranges3__45__cpo4swapE[1];
.extern .const .align 16 .b8 params[176];

.visible .entry __intersection__nn_multicast_2d()
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<29>;
	.reg .f64 	%fd<24>;
	.reg .b64 	%rd<24>;


	mov.u32 	%r3, 0;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	mov.u32 	%r5, 1;
	// begin inline asm
	call (%r4), _optix_get_payload, (%r5);
	// end inline asm
	// begin inline asm
	call (%r6), _optix_read_primitive_idx, ();
	// end inline asm
	ld.const.u64 	%rd5, [params+40];
	cvta.to.global.u64 	%rd6, %rd5;
	mul.wide.u32 	%rd7, %r2, 16;
	add.s64 	%rd1, %rd6, %rd7;
	ld.const.u64 	%rd8, [params+56];
	cvta.to.global.u64 	%rd9, %rd8;
	mul.wide.u32 	%rd10, %r6, 16;
	add.s64 	%rd2, %rd9, %rd10;
	ld.const.f64 	%fd1, [params+136];
	// begin inline asm
	call (%r8), _optix_get_launch_dimension_y, ();
	// end inline asm
	rem.u32 	%r13, %r6, %r8;
	ld.const.u64 	%rd11, [params+144];
	cvta.to.global.u64 	%rd12, %rd11;
	red.global.add.u32 	[%rd12], 1;
	// begin inline asm
	call (%r11), _optix_get_launch_index_y, ();
	// end inline asm
	setp.ne.s32 	%p1, %r11, %r13;
	@%p1 bra 	$L__BB0_7;

	ld.global.f64 	%fd3, [%rd2];
	sub.f64 	%fd4, %fd3, %fd1;
	ld.global.f64 	%fd5, [%rd1];
	setp.ltu.f64 	%p2, %fd5, %fd4;
	add.f64 	%fd6, %fd1, %fd3;
	setp.gtu.f64 	%p3, %fd5, %fd6;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_7;

	ld.global.f64 	%fd7, [%rd2+8];
	sub.f64 	%fd8, %fd7, %fd1;
	ld.global.f64 	%fd9, [%rd1+8];
	setp.ltu.f64 	%p5, %fd9, %fd8;
	add.f64 	%fd10, %fd1, %fd7;
	setp.gtu.f64 	%p6, %fd9, %fd10;
	or.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB0_7;

	ld.global.v2.f64 	{%fd11, %fd12}, [%rd1];
	ld.global.v2.f64 	{%fd15, %fd16}, [%rd2];
	sub.f64 	%fd19, %fd11, %fd15;
	sub.f64 	%fd20, %fd12, %fd16;
	mul.f64 	%fd21, %fd20, %fd20;
	fma.rn.f64 	%fd2, %fd19, %fd19, %fd21;
	mov.u32 	%r16, 2;
	// begin inline asm
	call (%r15), _optix_get_payload, (%r16);
	// end inline asm
	mov.u32 	%r18, 3;
	// begin inline asm
	call (%r17), _optix_get_payload, (%r18);
	// end inline asm
	cvt.u64.u32 	%rd13, %r15;
	cvt.u64.u32 	%rd14, %r17;
	bfi.b64 	%rd15, %rd13, %rd14, 32, 32;
	mov.b64 	%fd22, %rd15;
	setp.geu.f64 	%p8, %fd2, %fd22;
	@%p8 bra 	$L__BB0_5;

	mov.b64 	%rd16, %fd2;
	shr.u64 	%rd17, %rd16, 32;
	cvt.u32.u64 	%r20, %rd17;
	cvt.u32.u64 	%r22, %rd16;
	// begin inline asm
	call _optix_set_payload, (%r16, %r20);
	// end inline asm
	// begin inline asm
	call _optix_set_payload, (%r18, %r22);
	// end inline asm

$L__BB0_5:
	ld.const.u64 	%rd18, [params+128];
	cvta.to.global.u64 	%rd19, %rd18;
	ld.global.f64 	%fd23, [%rd19];
	add.s32 	%r24, %r4, 1;
	mov.u32 	%r23, 1;
	// begin inline asm
	call _optix_set_payload, (%r23, %r24);
	// end inline asm
	setp.gtu.f64 	%p9, %fd2, %fd23;
	@%p9 bra 	$L__BB0_7;

	ld.const.u64 	%rd20, [params+152];
	cvta.to.global.u64 	%rd21, %rd20;
	red.global.add.u32 	[%rd21], 1;
	ld.const.u64 	%rd22, [params+160];
	cvta.to.global.u64 	%rd23, %rd22;
	red.global.add.u32 	[%rd23], %r4;
	mov.f32 	%f1, 0f00000000;
	mov.u32 	%r26, 0;
	// begin inline asm
	call (%r25), _optix_report_intersection_0, (%f1, %r26);
	// end inline asm

$L__BB0_7:
	ret;

}
	// .globl	__anyhit__nn_multicast_2d
.visible .entry __anyhit__nn_multicast_2d()
{



	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm
	ret;

}
	// .globl	__raygen__nn_multicast_2d
.visible .entry __raygen__nn_multicast_2d()
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<10>;
	.reg .b32 	%r<124>;
	.reg .f64 	%fd<25>;
	.reg .b64 	%rd<56>;


	// begin inline asm
	call (%r123), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd51, %r123;
	ld.const.u64 	%rd2, [params+8];
	setp.le.u64 	%p1, %rd2, %rd51;
	@%p1 bra 	$L__BB2_16;

	ld.const.u64 	%rd26, [params];
	cvta.to.global.u64 	%rd3, %rd26;
	ld.const.v2.u64 	{%rd27, %rd28}, [params+32];
	cvta.to.global.u64 	%rd4, %rd28;
	ld.const.v2.u64 	{%rd31, %rd32}, [params+80];
	ld.const.u64 	%rd34, [params+72];
	cvta.to.global.u64 	%rd6, %rd34;
	cvta.to.global.u64 	%rd7, %rd31;
	cvta.to.global.u64 	%rd8, %rd27;
	ld.const.u64 	%rd35, [params+16];
	cvta.to.global.u64 	%rd9, %rd35;
	ld.const.u64 	%rd36, [params+128];
	cvta.to.global.u64 	%rd10, %rd36;
	ld.const.v2.f64 	{%fd7, %fd8}, [params+96];
	ld.const.v2.f64 	{%fd9, %fd10}, [params+112];
	sub.f64 	%fd3, %fd9, %fd7;
	sub.f64 	%fd4, %fd10, %fd8;
	// begin inline asm
	call (%r41), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r115), _optix_get_launch_dimension_y, ();
	// end inline asm
	add.s32 	%r118, %r115, -1;
	// begin inline asm
	call (%r120), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB2_2:
	shl.b64 	%rd38, %rd51, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r82, [%rd39];
	mul.wide.u32 	%rd40, %r82, 16;
	add.s64 	%rd41, %rd4, %rd40;
	cvt.rn.f64.s32 	%fd13, %r41;
	ld.global.f64 	%fd14, [%rd41];
	sub.f64 	%fd15, %fd14, %fd7;
	div.rn.f64 	%fd16, %fd15, %fd3;
	add.f64 	%fd17, %fd16, %fd13;
	ld.global.f64 	%fd18, [%rd41+8];
	sub.f64 	%fd19, %fd18, %fd8;
	div.rn.f64 	%fd20, %fd19, %fd4;
	add.f64 	%fd21, %fd20, %fd13;
	cvt.rn.f32.f64 	%f1, %fd17;
	cvt.rn.f32.f64 	%f2, %fd21;
	mov.f32 	%f6, 0f3F800000;
	mov.f32 	%f8, 0f00800000;
	mov.f32 	%f9, 0f00000000;
	mov.u32 	%r76, 255;
	mov.u32 	%r79, 1;
	mov.u32 	%r81, 4;
	mov.u32 	%r84, 2146435071;
	mov.u32 	%r85, -1;
	mov.u32 	%r113, 0;
	// begin inline asm
	call(%r43,%r44,%r45,%r46,%r47,%r48,%r49,%r50,%r51,%r52,%r53,%r54,%r55,%r56,%r57,%r58,%r59,%r60,%r61,%r62,%r63,%r64,%r65,%r66,%r67,%r68,%r69,%r70,%r71,%r72,%r73,%r74),_optix_trace_typed_32,(%r113,%rd32,%f1,%f2,%f9,%f9,%f9,%f6,%f9,%f8,%f9,%r76,%r113,%r113,%r79,%r113,%r81,%r82,%r113,%r84,%r85,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113);
	// end inline asm
	cvt.u64.u32 	%rd42, %r45;
	cvt.u64.u32 	%rd43, %r46;
	bfi.b64 	%rd12, %rd42, %rd43, 32, 32;
	mov.b64 	%fd5, %rd12;
	setp.eq.f64 	%p2, %fd5, 0d7FEFFFFFFFFFFFFF;
	shl.b64 	%rd44, %rd51, 3;
	add.s64 	%rd13, %rd6, %rd44;
	@%p2 bra 	$L__BB2_6;

	ld.global.u64 	%rd52, [%rd13];

$L__BB2_4:
	mov.b64 	%fd22, %rd52;
	setp.leu.f64 	%p3, %fd22, %fd5;
	@%p3 bra 	$L__BB2_6;

	atom.global.cas.b64 	%rd17, [%rd13], %rd52, %rd12;
	setp.ne.s64 	%p4, %rd17, %rd52;
	mov.u64 	%rd52, %rd17;
	@%p4 bra 	$L__BB2_4;

$L__BB2_6:
	add.s64 	%rd47, %rd7, %rd38;
	atom.global.add.u32 	%r117, [%rd47], 1;
	setp.ne.s32 	%p5, %r117, %r118;
	@%p5 bra 	$L__BB2_15;

	ld.global.u64 	%rd54, [%rd13];

$L__BB2_8:
	mov.b64 	%fd23, %rd54;
	setp.geu.f64 	%p6, %fd23, 0d0000000000000000;
	@%p6 bra 	$L__BB2_10;

	mov.u64 	%rd48, 0;
	atom.global.cas.b64 	%rd20, [%rd13], %rd54, %rd48;
	setp.ne.s64 	%p7, %rd20, %rd54;
	mov.u64 	%rd54, %rd20;
	@%p7 bra 	$L__BB2_8;

$L__BB2_10:
	mov.b64 	%fd6, %rd54;
	setp.eq.f64 	%p8, %fd6, 0d7FEFFFFFFFFFFFFF;
	@%p8 bra 	$L__BB2_14;
	bra.uni 	$L__BB2_11;

$L__BB2_14:
	atom.global.add.u32 	%r119, [%rd8], 1;
	mul.wide.u32 	%rd49, %r119, 4;
	add.s64 	%rd50, %rd9, %rd49;
	st.global.u32 	[%rd50], %r43;
	bra.uni 	$L__BB2_15;

$L__BB2_11:
	ld.global.u64 	%rd55, [%rd10];

$L__BB2_12:
	mov.b64 	%fd24, %rd55;
	setp.geu.f64 	%p9, %fd24, %fd6;
	@%p9 bra 	$L__BB2_15;

	atom.global.cas.b64 	%rd24, [%rd10], %rd55, %rd54;
	setp.eq.s64 	%p10, %rd24, %rd55;
	mov.u64 	%rd55, %rd24;
	@%p10 bra 	$L__BB2_15;
	bra.uni 	$L__BB2_12;

$L__BB2_15:
	add.s32 	%r123, %r120, %r123;
	cvt.u64.u32 	%rd51, %r123;
	setp.gt.u64 	%p11, %rd2, %rd51;
	@%p11 bra 	$L__BB2_2;

$L__BB2_16:
	ret;

}
	// .weak	_ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv
.weak .entry _ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv()
{



	ret;

}

