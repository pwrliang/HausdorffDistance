//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33567101
// Cuda compilation tools, release 12.3, V12.3.107
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_75
.address_size 64

	// .globl	__intersection__nn_2d
.weak .global .align 4 .b8 _ZZN4cuda3std3__48__detail21__stronger_order_cudaEiiE7__xform[16] = {3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 3};
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust6system6detail10sequential3seqE[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust8cuda_cub3parE[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust8cuda_cub10par_nosyncE[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_1E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_2E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_3E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_4E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_5E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_6E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_7E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_8E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders2_9E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust12placeholders3_10E[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20436thrust3seqE[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20434cuda3std3__48in_placeE[1];
.global .align 1 .b8 __nv_static_38__75f8b74c_16_shaders_nn_2d_cu_40bf2043__ZN47_INTERNAL_75f8b74c_16_shaders_nn_2d_cu_40bf20434cuda3std6ranges3__45__cpo4swapE[1];
.extern .const .align 8 .b8 params[120];

.visible .entry __intersection__nn_2d()
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<25>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<17>;


	mov.u32 	%r3, 0;
	// begin inline asm
	call (%r2), _optix_get_payload, (%r3);
	// end inline asm
	mov.u32 	%r5, 1;
	// begin inline asm
	call (%r4), _optix_get_payload, (%r5);
	// end inline asm
	// begin inline asm
	call (%r6), _optix_read_primitive_idx, ();
	// end inline asm
	ld.const.u64 	%rd3, [params+40];
	cvta.to.global.u64 	%rd4, %rd3;
	mul.wide.u32 	%rd5, %r2, 8;
	add.s64 	%rd1, %rd4, %rd5;
	ld.const.u64 	%rd6, [params+56];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.u32 	%rd8, %r6, 8;
	add.s64 	%rd2, %rd7, %rd8;
	ld.const.f32 	%f1, [params+88];
	ld.const.u64 	%rd9, [params+96];
	cvta.to.global.u64 	%rd10, %rd9;
	red.global.add.u32 	[%rd10], 1;
	ld.global.f32 	%f3, [%rd2];
	sub.f32 	%f4, %f3, %f1;
	ld.global.f32 	%f5, [%rd1];
	setp.ltu.f32 	%p1, %f5, %f4;
	add.f32 	%f6, %f1, %f3;
	setp.gtu.f32 	%p2, %f5, %f6;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_6;

	ld.global.f32 	%f7, [%rd2+4];
	sub.f32 	%f8, %f7, %f1;
	ld.global.f32 	%f9, [%rd1+4];
	setp.ltu.f32 	%p4, %f9, %f8;
	add.f32 	%f10, %f1, %f7;
	setp.gtu.f32 	%p5, %f9, %f10;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB0_6;

	ld.global.v2.f32 	{%f11, %f12}, [%rd1];
	ld.global.v2.f32 	{%f15, %f16}, [%rd2];
	sub.f32 	%f19, %f11, %f15;
	sub.f32 	%f20, %f12, %f16;
	mul.f32 	%f21, %f20, %f20;
	fma.rn.f32 	%f2, %f19, %f19, %f21;
	mov.u32 	%r9, 2;
	// begin inline asm
	call (%r8), _optix_get_payload, (%r9);
	// end inline asm
	mov.b32 	%f22, %r8;
	setp.geu.f32 	%p7, %f2, %f22;
	@%p7 bra 	$L__BB0_4;

	mov.b32 	%r11, %f2;
	// begin inline asm
	call _optix_set_payload, (%r9, %r11);
	// end inline asm

$L__BB0_4:
	ld.const.u64 	%rd11, [params+80];
	cvta.to.global.u64 	%rd12, %rd11;
	ld.global.f32 	%f23, [%rd12];
	add.s32 	%r13, %r4, 1;
	mov.u32 	%r12, 1;
	// begin inline asm
	call _optix_set_payload, (%r12, %r13);
	// end inline asm
	setp.gtu.f32 	%p8, %f2, %f23;
	@%p8 bra 	$L__BB0_6;

	ld.const.u64 	%rd13, [params+104];
	cvta.to.global.u64 	%rd14, %rd13;
	red.global.add.u32 	[%rd14], 1;
	ld.const.u64 	%rd15, [params+112];
	cvta.to.global.u64 	%rd16, %rd15;
	red.global.add.u32 	[%rd16], %r4;
	mov.f32 	%f24, 0f00000000;
	mov.u32 	%r15, 0;
	// begin inline asm
	call (%r14), _optix_report_intersection_0, (%f24, %r15);
	// end inline asm

$L__BB0_6:
	ret;

}
	// .globl	__anyhit__nn_2d
.visible .entry __anyhit__nn_2d()
{



	// begin inline asm
	call _optix_terminate_ray, ();
	// end inline asm
	ret;

}
	// .globl	__raygen__nn_2d
.visible .entry __raygen__nn_2d()
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<120>;
	.reg .b64 	%rd<24>;


	// begin inline asm
	call (%r118), _optix_get_launch_index_x, ();
	// end inline asm
	cvt.u64.u32 	%rd23, %r118;
	ld.const.u64 	%rd2, [params+8];
	setp.le.u64 	%p1, %rd2, %rd23;
	@%p1 bra 	$L__BB2_8;

	ld.const.u64 	%rd11, [params];
	cvta.to.global.u64 	%rd3, %rd11;
	ld.const.u64 	%rd12, [params+40];
	cvta.to.global.u64 	%rd4, %rd12;
	ld.const.u64 	%rd5, [params+72];
	ld.const.u64 	%rd13, [params+80];
	cvta.to.global.u64 	%rd6, %rd13;
	ld.const.u64 	%rd14, [params+32];
	cvta.to.global.u64 	%rd7, %rd14;
	ld.const.u64 	%rd15, [params+16];
	cvta.to.global.u64 	%rd8, %rd15;
	// begin inline asm
	call (%r115), _optix_get_launch_dimension_x, ();
	// end inline asm

$L__BB2_2:
	shl.b64 	%rd17, %rd23, 2;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.u32 	%r82, [%rd18];
	mul.wide.u32 	%rd19, %r82, 8;
	add.s64 	%rd20, %rd4, %rd19;
	ld.global.v2.f32 	{%f11, %f12}, [%rd20];
	mov.u32 	%r113, 0;
	mov.u32 	%r79, 1;
	mov.f32 	%f7, 0f3F800000;
	mov.f32 	%f9, 0f00800000;
	mov.f32 	%f10, 0f00000000;
	mov.u32 	%r76, 255;
	mov.u32 	%r81, 3;
	mov.u32 	%r84, 2139095039;
	// begin inline asm
	call(%r43,%r44,%r45,%r46,%r47,%r48,%r49,%r50,%r51,%r52,%r53,%r54,%r55,%r56,%r57,%r58,%r59,%r60,%r61,%r62,%r63,%r64,%r65,%r66,%r67,%r68,%r69,%r70,%r71,%r72,%r73,%r74),_optix_trace_typed_32,(%r113,%rd5,%f11,%f12,%f10,%f10,%f10,%f7,%f10,%f9,%f10,%r76,%r113,%r113,%r79,%r113,%r81,%r82,%r113,%r84,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113,%r113);
	// end inline asm
	mov.b32 	%f1, %r45;
	setp.neu.f32 	%p2, %f1, 0f7F7FFFFF;
	@%p2 bra 	$L__BB2_4;
	bra.uni 	$L__BB2_3;

$L__BB2_4:
	ld.global.u32 	%r119, [%rd6];

$L__BB2_5:
	mov.b32 	%f13, %r119;
	setp.geu.f32 	%p3, %f13, %f1;
	@%p3 bra 	$L__BB2_7;

	atom.global.cas.b32 	%r38, [%rd6], %r119, %r45;
	setp.ne.s32 	%p4, %r38, %r119;
	mov.u32 	%r119, %r38;
	@%p4 bra 	$L__BB2_5;
	bra.uni 	$L__BB2_7;

$L__BB2_3:
	atom.global.add.u32 	%r114, [%rd7], 1;
	mul.wide.u32 	%rd21, %r114, 4;
	add.s64 	%rd22, %rd8, %rd21;
	st.global.u32 	[%rd22], %r43;

$L__BB2_7:
	add.s32 	%r118, %r115, %r118;
	cvt.u64.u32 	%rd23, %r118;
	setp.gt.u64 	%p5, %rd2, %rd23;
	@%p5 bra 	$L__BB2_2;

$L__BB2_8:
	ret;

}
	// .weak	_ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv
.weak .entry _ZN3cub17CUB_200200_750_NS11EmptyKernelIvEEvv()
{



	ret;

}

